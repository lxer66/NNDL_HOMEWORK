# Assignment3 实验报告

## 1. 实验目的和作业完成情况

### 1.1 实验目的
**本实验旨在构建一个基于卷积神经网络的图像分类器，完成CIFAR-10数据集的分类任务。通过实现ResNet-20模型，深入理解卷积神经网络的基本结构、代码实现及训练过程，通过K折交叉验证为神经网络选择超参数组合，应用和对比Dropout和多种Normalization方法，使用普通的模型和方法训练。**

**在模型和算法的优化上，参考ResNet原始论文[^1]和Github开源项目[^2]，使用了论文里提出的训练方法，复现了ResNet原始论文中ResNet-20在CIFAR-10数据集上的结果，大幅提升基础模型性能。**

### 1.2 文件结构
具体来说，文件的结构如下：
```
assignment3/
├── assignment_instruction.md          # 实验报告文档
├── datasets.py                        # 数据集加载和预处理
├── homework_content.md                # 作业要求说明
├── k_fold_cross_valiation.py          # K折交叉验证实现
├── k_fold_cross_valiation.txt         # K折交叉验证结果记录
├── model.py                           # 基础模型定义（ResNet-20）
├── models/                            # 训练好的模型文件目录
│   ├── optimized_resnet20.pth         # 优化训练后的模型
│   ├── resnet20_lr*.pth               # 不同参数组合训练的模型
├── optimization_work.py               # 优化模型和算法的训练实现
├── pictures/                          # 训练过程曲线图
│   ├── resnet20_lr*.png               # 不同参数组合的训练曲线（包括优化训练后的模型的训练曲线）
├── test.py                            # 模型测试脚本
├── test.txt                           # 模型测试结果记录
├── test_set/                          # 测试数据集（因为训练集和测试集较大，暂时未上传Github，也未提交至云平台）
├── train_compare.py                   # 基础训练droput和多种Normalization对比实现
└── train_set/                         # 训练数据集（因为训练集和测试集较大，暂时未上传Github，也未提交至云平台）
```

### 1.3 作业完成情况

我使用`dataset.py`和`model.py`完成了数据集加载、预处理、基础模型定义，使用`k_fold_cross_valiation.py`进行k折交叉验证选择超参数组合，将结果记录在`k_fold_cross_valiation.txt`，选择出对于基础模型最合适的超参数。然后使用`train_compare.py`和`test.py`实现了dropout和多种Normalization训练、测试、比较，将结果记录在`test.txt`。完整地完成了作业的基础要求，即

*  理解卷积神经网络的基本结构、代码实现及训练过程

* 应用dropout和多种normalization方法，理解它们对模型泛化能力的影响

* 理解如何通过交叉验证，为神经网络找到最好的hyperparameters

对于附加题

* 在训练网络的过程中，可根据需要自由尝试其它提升性能的方法，例如通过增加模型层数、使用不同的正则化方法、使用模型集成等 (+5 points)  
  我使用ResNet原始论文的方法，通过`optimization_work.py`复现了论文的结果，实现了模型性能的大幅提升，很好的完成了附加题。


## 2. 实验方法与实现

### 2.1 基础网络模型设计

本实验基于ResNet原始论文，基于ResNet的残差结构设计了一个20层的卷积神经网络(ResNet-20)。网络包含以下主要组件：

1. 初始卷积层：使用3×3卷积核，输出通道数为16
2. 残差块：共9个残差块，分为3组，每组3个残差块
   - 第一组：输入输出通道数均为16
   - 第二组：输入通道数16，输出通道数32，第一个残差块进行下采样
   - 第三组：输入通道数32，输出通道数64，第一个残差块进行下采样
3. 分类器：全局平均池化+全连接层

### 2.2 残差块实现

残差块是ResNet的核心组件，其设计解决了深度神经网络训练过程中的梯度消失问题。在本实验中，残差块的实现如下：

1. **结构设计**：
   - 每个残差块包含两个3×3卷积层，以及一个残差连接
   - 第一个卷积层后接归一化层和ReLU激活函数
   - 第二个卷积层后接归一化层，但不立即应用激活函数
   - 残差连接将输入（可能需要调整维度）加到第二个卷积层的输出上
   - 最后对相加结果应用ReLU激活函数

2. **维度匹配**：
   - 当输入输出维度一致时，直接进行残差连接
   - 当输入输出维度不一致时（如下采样情况），通过1×1卷积调整维度

3. **代码实现细节**：
   - 构造函数中通过`downsample`参数判断是否需要下采样
   - 使用`get_norm_layer`函数动态获取不同类型的归一化层
   - 在前向传播中，首先保存输入作为identity，然后依次通过两个卷积-归一化-激活操作
   - 当需要下采样时，通过1×1卷积和归一化处理identity，使其维度与输出匹配
   - 最后将处理后的identity与卷积输出相加，再应用ReLU激活函数

4. **残差优势**：
   - 残差连接使得网络可以学习残差映射而不是直接映射，缓解了梯度消失问题
   - 允许训练更深的网络，提高了模型表达能力
   - 通过维度匹配机制，支持网络在不同阶段进行下采样

这种设计使得网络可以训练得更深，同时避免了传统深度网络中的梯度消失问题，大大提高了深度网络的训练效果。

### 2.3 k-折交叉验证和超参数选择

为了选择最优的超参数组合，我采用了K折交叉验证的方法。具体实现细节如下：

1. **K折交叉验证策略**：
   - 采用3折交叉验证，将训练集划分为3个大小相等的子集（基于计算资源和时间的考虑，如果条件允许应该使用更多的折）
   - 每次使用2个子集作为训练集，1个子集作为验证集
   - 重复3次，确保每个子集都被用作验证集一次
   - 最终结果为3次最高验证准确率的平均值

2. **超参数搜索空间**：
   - 学习率：[0.1, 0.01, 0.001]
   - 权重衰减系数（L2正则化）：[0.001, 0.0001, 0.00001]
   - momentum=0.9
   - 训练轮数：100轮
   - 批次大小：128
   - 共9个超参数组合

3. **实现细节**：
   - 使用`numpy.random.permutation`对数据集进行随机打乱
   - 固定随机种子（42）以确保实验可复现
   - 在每个epoch结束后评估验证集性能
   - 记录训练损失、训练准确率、验证损失和验证准确率
   - 选择验证准确率最高的模型进行最终评估

4. **交叉验证过程**：
   - 对于每组超参数组合，执行完整的3折交叉验证
   - 每个fold训练100个epoch，每10个epoch输出一次训练和验证结果
   - 记录每个fold的最终验证准确率
   - 计算3个fold的平均准确率和标准差作为该超参数组合的性能指标

5. **实验结果**：
   - 通过实验结果（详见[3.1 超参数选择结果](#31-超参数选择结果保存在k_fold_cross_validationtxt中)）发现，学习率为0.1，权重衰减为1e-5时效果最佳
   - 该组合在3折交叉验证中的平均验证准确率为81.3%

### 2.4 训练结果和正则化方法对比

为了研究不同正则化方法对模型性能的影响，我实现了多种Normalization技术：

1. **Batch Normalization (BN)**
2. **Layer Normalization (LN)**
3. **Group Normalization (GN)**
4. **Instance Normalization (IN)**
5. **Local Response Normalization (LRN)**
6. **不使用Normalization**

同时，我在固定使用Batch Normalization的情况下测试了不同Dropout率(0, 0.1, 0.5)的效果。
上述的对比实验使用的训练配置来自[2.3 k-折交叉验证和超参数选择](#23-k-折交叉验证和超参数选择)，即：学习率0.1，momentum=0.9，权重衰减为1e-5，训练轮数100，批量大小128。

实验结果对比详见[3.2不同正则化方法比较](#32-不同正则化方法比较)。

### 2.5 优化模型与训练策略

参考ResNet原始论文[^1]和Github开源项目[^2]的实现，我在基础模型和训练策略的基础上进行了多项优化，具体改进如下：

1. **优化模型结构**：
   - 所有卷积层均设置`bias=False`，因为在归一化层后使用偏置是多余的，可以减少参数数量。这种优化可以降低模型复杂度，减少过拟合风险。
   - 在初始卷积层后添加BatchNorm层。这有助于稳定训练过程，加速收敛并提高模型性能。

2. **优化训练策略**：
   - 使用Kaiming初始化方法替代Xavier初始化。Kaiming初始化更适合ReLU激活函数，能够更好地保持前向传播过程中信号的方差，避免梯度消失或爆炸问题。
   - 使用学习率0.1，动量0.9，权重衰减1e-4的SGD优化器。较高的学习率有助于快速收敛，动量项可以加速优化过程并减少震荡，权重衰减起到正则化作用防止过拟合。
   - 引入学习率衰减策略(MultiStepLR)，在第100和150轮时将学习率降低为原来的0.1倍。这种策略在训练初期快速收敛，后期精细调整，有助于模型达到更优解。在训练图像中，两次学习率衰减的时候精度的显著提升可以直接体现这点。
   - 增加训练轮数至200轮。更长的训练时间使模型能够充分收敛，达到更好的性能。
   - 采用数据增强技术，包括随机水平翻转和随机裁剪(随机裁剪32x32图像及其4像素填充)。数据增强可以增加训练数据的多样性，提高模型的泛化能力。
   - 使用ImageNet数据集的均值和标准差进行标准化处理。这种标准化方式在许多计算机视觉任务中被证明是有效的，有助于模型更好地适应输入数据分布。

3. **优化实现细节**：
   - 使用更高效的优化器参数设置。合理的优化器参数可以显著加快训练速度并提高模型性能。
   - 在训练过程中实时打印当前学习率，便于监控训练过程。这有助于了解模型训练状态，及时发现训练异常。
   - 优化模型保存策略，统一保存为optimized_resnet20.pth文件。规范的模型保存方式便于后续测试和部署。

**这些优化措施显著提升了模型性能，使测试准确率从基础模型的约84%提升至91.94%。**

### 2.6 实验执行命令
```
python dataset.py
python k_fold_cross_validation.py
python train_compare.py
python test.py
python optimization_work.py
```
## 3. 实验结果

### 3.1 超参数选择结果（保存在k_fold_cross_validation.txt中）

通过3折交叉验证，我对不同的超参数组合进行了实验，具体结果如下表所示：

| 学习率 | 权重衰减 | 3折平均验证准确率 | 各折验证准确率           |
|--------|----------|-------------------|--------------------------|
| 0.1    | 0.001    | 78.73%            | [79.16%, 77.97%, 79.07%] |
| 0.1    | 0.0001   | 79.35%            | [79.43%, 79.07%, 79.54%] |
| 0.1    | 1e-05    | 81.30%            | [81.51%, 80.64%, 81.76%] |
| 0.01   | 0.001    | 77.14%            | [77.75%, 76.95%, 76.72%] |
| 0.01   | 0.0001   | 77.43%            | [78.51%, 76.75%, 77.04%] |
| 0.01   | 1e-05    | 76.96%            | [77.95%, 76.30%, 76.63%] |
| 0.001  | 0.001    | 65.97%            | [67.21%, 65.10%, 65.58%] |
| 0.001  | 0.0001   | 65.88%            | [66.73%, 65.34%, 65.56%] |
| 0.001  | 1e-05    | 65.66%            | [67.45%, 64.46%, 65.05%] |

从表中可以看出，学习率为0.1、权重衰减为1e-05的组合取得了最佳的验证准确率81.30%。

### 3.2 不同正则化方法比较（保存在test.txt中）

在测试集上的准确率如下：

| 正则化方法 | Dropout=0 | Dropout=0.1 | Dropout=0.5 |
|------------|-----------|-------------|-------------|
| BN         | 84.11%    | 82.98%      | 83.38%      |
| LN         | 84.10%    | -           | -           |
| GN         | 83.79%    | -           | -           |
| IN         | 83.74%    | -           | -           |
| LRN        | 82.82%    | -           | -           |
| None       | 83.94%    | -           | -           |

### 3.3 优化训练结果（保存在test.txt中）

**使用优化后的训练策略，模型在测试集上的准确率达到了91.94%，显著优于基础版本，error值为8.06%，达到甚至优于了ResNet原始论文里的8.75%，成功复现了论文的结果。**

## 4. 实验分析

### 4.1 超参数选择分析

通过3折交叉验证的大量实验，我发现超参数对模型性能有显著影响：

1. **学习率的影响**：
   - 学习率为0.1时，模型训练效果最佳，验证准确率最高可达81.30%
   - 学习率为0.01时，模型训练速度较慢，但是训练集最后仍然能够达到较高准确率，验证准确率有所下降，
   - 学习率为0.001时，模型训练速度过慢，验证准确率显著下降至约65%

2. **权重衰减的影响**：
   - 在学习率为0.1时，权重衰减为1e-05的效果优于其他值
   - 过高的权重衰减(0.001)会限制模型的学习能力
   - 过低的权重衰减会导致过拟合

3. **超参数组合分析**：
   - 最佳超参数组合(学习率0.1，权重衰减1e-05)在3折交叉验证中的平均验证准确率为81.3%，是最好的结果
   - 但是从K折交叉验证的结果可以大胆猜测，如果将权重衰退进一步调小甚至设置为0，验证精度会更高，我将在[4.4](#44-关于我对实验的思考)中给出我的理解。

### 4.2 正则化方法分析

通过对不同正则化方法的对比实验，我得出以下结论：

1. **Batch Normalization (BN)效果最佳**：
   - BN在所有Normalization方法中取得了最好的效果，测试准确率达到84.11%
   - BN通过规范化每层的输入，减少了内部协变量偏移，加速了训练过程

2. **不同Normalization方法的比较**：
   - Layer Normalization (LN)和Group Normalization (GN)效果次之，分别为84.10%和83.79%
   - Instance Normalization (IN)和Local Response Normalization (LRN)效果略低一点点，但没有显著降低
   - 不使用Normalization时准确率为83.94%，比使用除了Batch Normalization和Layer Normalization之外的正则化方法更好，这说明了一些问题，我将在[4.4](#44-关于我对实验的思考)中给出我的理解。
3. **Dropout的影响**：
   - 对于ResNet模型，实际上不适合使用Dropout，因为Dropout会引入额外的正则化效果，而ResNet本身已经提供了足够的正则化效果
   - 不论使用Dropout=0.1还是0.5都不如使用Dropout=0，可以说明上述的观点。
   - 而Dropout=0.5优于Dropout=0.1，这也是一个有意思的问题，我将在[4.4](#44-关于我对实验的思考)中给出我的理解。

### 4.3 优化训练策略分析

详细的优化训练策略分析，可以参考[2.5 优化模型与训练策略](#25-优化模型与训练策略)。
这里主要对训练时的图像做分析：
![训练图像](.\pictures\resnet20_lr0.1_momentum0.9_wd0.0001_dropout0_bnnormalization.png)

在epoch100前，训练精度和训练损失分别逐步上升和下降，趋于平台期，在epoch100时，学习率从0.1下降到0.01，训练损失有明显下降，训练精度有明显上升（约5%）；然后再次逐渐进入平台期，在epoch150时，学习率从0.01下降到0.001，训练损失再次有明显下降，训练精度再次有明显上升（约2%），最后达到99%以上的精度和$1e-4$量级的训练损失。**这种现象说明学习率衰减策略有效地帮助模型跳出局部最优并继续优化，每次学习率下降后模型都能找到更优的参数空间区域，这也是为什么多阶段学习率衰减能显著提升模型性能的重要原因。**

### 4.4 关于我对实验的思考

1. **我的k折交叉验证实验相对失败：通过分析`k_fold_cross_valiation.txt`中的详细数据，可以发现一个明显的问题：几乎所有k折交叉验证实验中训练准确率都远高于验证准确率，这表明模型出现了严重的过拟合现象。受限于基础模型的训练方法和数据预处理的朴素，在k折交叉验证实验的时候不论使用什么样的学习率和权重衰退的组合都会导致严重过拟合或者训练精度过低这两种情况，在这样的情形下，k折交叉验证一定程度上失去了其应有的作用——即通过验证集表现来评估模型的泛化能力。这种情况下，因为所有的参数组合都面临同样的过拟合问题，验证集表现无法真实反映模型的优劣，导致我们无法通过交叉验证选择出真正最优的参数组合。使用越小的学习率（因为学习率固定不调整）或者使用越大的权重衰退，只会导致验证精度更劣。事实上，如果想要改变这个情况，也就是要做一个合理的真正的k折交叉验证，一方面需要增大k的值（实验使用的`k=3`实际上过小），一方面要搜索更大的参数组合空间（即更多的参数更多的值的组合），更重要的是使用更好的训练策略和数据增强。只有先在确保尽可能不出现过拟合的情况，才能使得k折交叉验证起到真正选择参数的作用，这在我们的优化训练中得到了验证（没有过拟合现象）。不过受限于计算资源和时间，我的k折交叉验证实验实现和效果只能限于此。**

2. **不使用Normalization时的效果比一些使用的效果好：原理和第1点类似，在严重过拟合或者训练精度过低这两种结果的情况下，添加任何正则化技术都可能进一步限制模型的学习能力，反而导致性能下降。Batch Normalization（84.11%）和Layer Normalization（84.10%）表现相对较好，这可能是因为它们不仅起到了正则化作用，更重要的是改善了训练过程的稳定性，加速了收敛。**

3. **Dropout=0.5优于Dropout=0.1：使用Dropout的效果更差，除了和第1点类似的原因，还有原因是，一方面是因为ResNet的残差连接本身就提供了一定的正则化效果，再加入Dropout可能导致正则化过度，影响模型的学习能力，这导致它们不如Dropout=0的情况；另一方面Dropout=0.5引入了更多的随机性，这种随机性可能有助于模型跳出局部最优，可能会导致优于0.1的情形。**

4. **在优化后的训练策略中，通过更好的训练方法和正则化技术的组合，我们成功避免了过拟合问题，使模型达到了91.94%的高准确率，这说明选择合适的训练策略比单纯调整某个或某些超参数更为重要。**

## 5. 实验总结

**本实验设计和实现基于ResNet-20的CIFAR-10图像分类器。我首先实现了基础的ResNet-20模型，通过K折交叉验证选择了超参数组合（学习率0.1，权重衰减1e-5），并对比了多种Normalization方法和Dropout的影响。随后，我参考ResNet原始论文和Github开源项目对模型和训练策略进行了优化，包括移除冗余bias参数、使用Kaiming初始化、引入学习率衰减策略、增加训练轮数和采用数据增强技术等，使模型测试准确率从约84%提升至91.94%。
通过本次实验，我加深了对卷积神经网络结构、K折交叉验证、正则化、训练过程的理解，以及对常用的经典的模型优化以及训练策略有了更多的认识和实践的经验，同时实现了对论文一部分内容的复现，收获颇多。**

**大模型使用情况：在本assignment中，大模型主要用于查找资料，获得建议，撰写注释和非代码的文档。代码中少数的函数和细节使用了大模型的辅助。代码中的大部分内容均为自己实现或者参考Github项目[^2].**

## 参考文献
[^1]: Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. [arXiv:1512.03385](https://arxiv.org/abs/1512.03385)
[^2]: akamaster: pytorch_resnet_cifar10. GitHub. [akamaster/pytorch_resnet_cifar10](https://github.com/akamaster/pytorch_resnet_cifar10)